---
title: "Tecnología Digital VI: Trabajo Práctico 1"
author: "Emiliana Verdun, Mariana Zunino"
date: "2024-09-01"
output: pdf_document
---

```{r libr, echo=FALSE}
#install.packages("rpart")
library(rpart)
library(rpart.plot)
#install.packages("Metrics")
library(Metrics)
```

## Introducción

Se ha tomado para la realización del trabajo un dataset de más de 900.000 observaciones que ha sido recortado a 50000 observaciones, que tiene como objetivo la predicción de alcoholismo en una persona a partir de diferentes predictores respectivos a su salud. El valor que toma la predicción es "Y" la persona es alcoholica o "N" si no lo es.
Dicho conjunto de datos fue obtenido en Kaggle y se encuentra disponible en el siguiente link: https://www.kaggle.com/datasets/sooyoungher/smoking-drinking-dataset


Los atributos predictores descriptos en el dataset son 22 e incluyen: 
"Age" (numérico), "Sex" (Categórico), "Height", "Weight", visión en cada ojo (binario: 0=normal, 1=abnormal), escucha en cada oído (binario: 0=normal, 1=abnormal), valores de colesterol, presión arterial y diferentes parámetros relevantes en salud.

La elección del dataset se debe a que resulta de caracter interesante y científico, además del hecho de que está muy completo y no cuenta con valores faltantes. Su carácter científico permite a la vez realizar divisiones razonables a la hora de la toma de decisiones dentro del árbol.



# Ejercicio 2
Se cargan los datos a utilizar.

```{r}
#setwd('c:/Users/Mariana/OneDrive/Documentos/TDVI/TPs')
data <- read.csv("drinking_dataset.csv")
```

Descripción de las variables principales del dataset
```{r}
summary(data)
str(data)
```
Se convierte a factor las columnas de caracteres de "sex" y la columna para la predicción de "DRK_YN".
Se convierte la columna de observaciones de clase en binario, para poder luego utilizar correctamente las métricas.
```{r}
data$sex <- as.factor(data$sex)
data$DRK_YN <- ifelse(data$DRK_YN == "Y", 1, 0)
```


## Visualizaciones

```{r plots}
cant_f <- sum(data$sex == "Female")
cant_m <- sum(data$sex == "Male")
cant_alcoholico_f <- sum(data$sex == "Female" & data$DRK_YN == 1)
cant_alcoholico_m <- sum(data$sex == "Male" & data$DRK_YN == 1)
cant_NO_alcoholico_f <- sum(data$sex == "Female" & data$DRK_YN == 0)
cant_NO_alcoholico_m <- sum(data$sex == "Male" & data$DRK_YN == 0)

#cant_f
#cant_alcoholico_f
#cant_NO_alcoholico_f
#cant_m
#cant_alcoholico_m
#cant_NO_alcoholico_m

prop_alcoholicos <- ((cant_alcoholico_f + cant_alcoholico_m)/(cant_f + cant_m))
prop_NO_alcoholicos <- ((cant_NO_alcoholico_f + cant_NO_alcoholico_m)/(cant_f + cant_m))

prop_alcoholicos_f <- cant_alcoholico_f/cant_f
prop_NO_alcoholicos_f <- cant_NO_alcoholico_f/cant_f

prop_alcoholicos_m <- cant_alcoholico_m/cant_m
prop_NO_alcoholicos_m <- cant_NO_alcoholico_m/cant_m

prop_alcoholicos
prop_NO_alcoholicos
prop_alcoholicos_f
prop_NO_alcoholicos_f
prop_alcoholicos_m
prop_NO_alcoholicos_m
```

```{r}
prop_alc <- c(prop_alcoholicos_f, prop_alcoholicos_m)
sex <- c("Femenino", "Masculino")
val_max <- max(prop_alc)


# Crear el gráfico de barras
barplot(prop_alc, names.arg = sex, col = "lightblue",
        main = "Proporción de Alcoholicos por Sexo", xlab = "Sexo",
        ylim = c(0, val_max + 0.2))
```


``` {r}
edades_alc <- data$age[data$DRK_YN == 1]
hist(edades_alc, main="Histograma de Edades (Solo Alcohólicos)", 
     xlab="Edades", ylab="Frecuencia", col="lightblue", border="black")
```



# Ejercicio 3
```{r division, echo=FALSE}
set.seed(1234)
nobs <- nrow(data)
#obtengo el 70% del dataset y se lo asigno a train
itrain <- sample(nobs, 0.7*nobs)
train <- data[itrain, ]
resto <- data[-itrain,]

#con el resto del dataset consigo 15% para validación y 15% para test
nobs2 <- nrow(resto) 
ival <- sample(nobs2, 0.5*nobs2)
val <- resto[ival,]
test <- resto[-ival,]
```

```{r}
set.seed(1234)
tree <- rpart(formula = DRK_YN ~ sex + age + height + weight + waistline + sight_left + sight_right + hear_left + hear_right + SBP + DBP + BLDS + tot_chole + HDL_chole + LDL_chole + triglyceride + hemoglobin + urine_protein + serum_creatinine + SGOT_AST + SGOT_ALT + gamma_GTP + SMK_stat_type_cd,
              data = train, 
            method = "class")
```

```{r hiperparametros}
tree$control
```
Como hiperparámetro por defecto se toma un valor de minsplit = 20, es decir, que en una hoja del árbol deben haber por lo menos 20 observaciones para poder realizar un split y crear nuevas regiones.
Por otro lado, se establece que como mínimo una hoja debe tener 7 observaciones con el valor default de minbucket y que como máxima profundidad el árbol puede tener 30 niveles.
Además, aparecen otros parámetros como un cp de 0.01 y xval de 10. --¿Es necesario poner todos y que son?

Con estos hiperparámetros por defecto y con el árbol obtenido, obtenemos la siguiente visualización del árbol de clasificación.
```{r grafico_arbol}
rpart.plot(tree)
```

El árbol obtenido con los parámetros default tiene una profundidad de 3, siendo el primer split realizado a partir del sexo de la persona. Como se pudo visualizar en uno de los gráficos del punto 2, las personas de sexo masculino tienen una tendencia mucho mayor al alcoholismo que las de sexo femenino. Se puede ver en este primer split que a todas las muestras de sexo femenino las clasifica como no alcohólicas, de manera un poco brusca teniendo en cuenta que sí hay cierta proporción de mujeres alcoholicas en los datos. 
Luego, se continúan generando más regiones de decisión con los casos de sexo masculino. Se toma como segundo criterio en los hombres si el valor de gamma_GTP es menor a 36: en el caso que no lo sea, clasifica el individuo como alcohólico; si lo es, entra en cuestión la edad del individuo. Si la edad es mayor o igual 53 con un gamma_GTP menor a 36, esa persona no es considerada alcohólica por el modelo; en cambio, si tiene una edad menor a 53, se considera que sí lo es.
A fin de cuentas, el modelo clasifica al 57% de los casos como no alcohólicos mientras que el otro 43% es considerado alcohólico. Esta clasificación tiene ciertos errores y generalizaciones que afectan a su rendimiento y se buscará mejorar en los próximos ejercicios.

## Importancia de los atributos e identificación de variables principales
```{r}
variable_importance <- tree$variable.importance
barplot(sort(variable_importance, decreasing = TRUE), 
        main = "Importancia de las Variables Predictoras",
        xlab = "Variables",
        ylab = "Importancia",
        las = 2,          # Rotar las etiquetas en el eje x
        col = "lightblue")
```
En este gráfico se puede visualizar cuáles variables son las más coincidentes o que mayor ayudan a clasificar a la muestra, siendo el sexo el más importante, aunque gamma_GTP y edad, que son las otras 2 variables visibles en el árbol formado no parecen tener tanta importancia y esto resulta un poco chocante.

# Ejercicio 4
Con tal de poder analizar el rendimiento del modelo con los hiperparámetros default, se prueban diferentes métricas a partir de predicciones realizadas sobre el conjunto de test tomado del dataset.
```{r}
prediccion_test <- predict(tree, test, type="class")
prediccion_probas <- predict(tree,test,type="prob")

#se agrupan los valores reales y las predicciones en dataframe de resultados
resultados <- data.frame(
  obs = test$DRK_YN, #valor verdadero
  pred = prediccion_test, #valor predicho
  prob = prediccion_probas #probas predichas
)
```

Una vez obtenidos estos resultados, se puede proceder a realizar un análisis de performance del modelo, para lo cual se explorarán la matriz de confusión resultante y los valores de accuracy, precision y recall, el F1-score y el valor de AUC-ROC.
```{r matrizConfusion}
matriz_confusion <- table(Real=test$DRK_YN, Predicho=prediccion_test)
matriz_confusion
```
Se puede visualizar en la matriz cómo, para valores reales negativos (personas no alcohólica), las predicciones son bastante mejores que para predecir aquellas que sí lo son realmente. Esto puede deberse al enfoque generalizador y un poco tosco del modelo no refinado, que por ejemplo clasifica a todas las personas del sexo femenino como no alcohólicas y de esta manera pasa por alto muchos casos donde sí lo son, causando falsos negativos.

```{r scores}
true_positive <- matriz_confusion[2,2]
true_negative <- matriz_confusion[1,1]
false_positive <- matriz_confusion[1,2]
false_negative <- matriz_confusion[2,1]
pred_proba_pos <- prediccion_probas[, "1"] #calculo de probabilidades para clase "1",                                             es decir "Y"
observado <- test$DRK_YN

accuracy <- (true_positive+true_negative)/sum(matriz_confusion) #(TP + TN) / Total
precision <- true_positive/(true_positive+false_positive)       #TP / (TP+FP)
recall <- true_positive/(true_positive+false_negative)          #TP / (TP+FN)
f1_score <- (2*precision*recall)/(precision+recall)           # 2*prec*rec/(prec+rec)
auc_roc <- auc(observado, pred_proba_pos)
```
Con el modelo propuesto en el punto 3, sin tocar los hiperparámetros, se llega a un accuracy de `r accuracy`, es decir, del total de predicciones sobre el conjunto de test se predijo correctamente esa proporción. Luego, de la cantidad que fueron predichas como 1 (alcoholico), efectivamente se acertó con una precision de `r precision`; y de los casos que verdaderamente pertenecen a la clase 1, se predijo como tal (recall) una proporción de `r recall`. Con estas 2 métricas, obtenemos el f1-score, que tiene un valor de `r f1_score`.
Por último, interesa la métrica del AUC-ROC, es decir, el área bajo la curva de ROC (mide la relación entre verdaderos positivos y falsos positivos) que permite indicar la capacidad predictora del modelo. Esta tomó un valor de `r auc_roc`.

En general, no parece tan malo para ser el modelo default pero puede ser mucho mejor optimizado adaptando los hiperparámetros.


# Ejercicio 5
Para la optimización del modelo, se toman ciertos valores elegidos a mano con tal de realizar una búsqueda de parámetros que optimicen el modelo a partir de grid search.
Se establecen cp y xval en 0 y se exploran diferentes combinaciones de maxdepth, minsplit y minbucket.
Se almacena el mejor resultado (aquellos valores con los cuales se obtenga el modelo con el cual se maximiza AUC-ROC con las predicciones sobre el conjunto de validación) y se entrena el modelo con esos valores como hiperparámetros.

```{r}
optimizacion_arbol <- function(train, val, test, valores_depth, valores_bucket, valores_split){
    #Se crea dataframe para almacenar resultados de combinaciones y poder visualizar
    resultados <- data.frame(maxdepth = integer(), minsplit = integer(), minbucket =                   integer(), auc = numeric())
    
    #Valores de cp y xval fijos en 0
    cp = 0
    xval = 0
    
    #Grid search
    for (d in valores_depth){
      for (b in valores_bucket){
        for (s in valores_split){
          tree <- rpart(formula=DRK_YN ~ sex + age + height + weight + waistline +                     sight_left + sight_right + hear_left + hear_right + SBP + DBP +                      BLDS + tot_chole + HDL_chole + LDL_chole + triglyceride +                            hemoglobin + urine_protein + serum_creatinine + SGOT_AST + SGOT_ALT                   + gamma_GTP + SMK_stat_type_cd,
              data = train, method = "class",
              control = rpart.control(
              cp = 0,          
              xval = 0,        
              maxdepth = d,
              minsplit = s,
              minbucket= b
            )
          )
          predicted_probs <- predict(tree, val, type = "prob")[, "1"]
          observed_classes <- val$DRK_YN
          auc_valor <- auc(observed_classes, predicted_probs)
        
          resultados <- rbind(resultados, data.frame(maxdepth = d, minsplit = s,                                      minbucket = b, auc = auc_valor))
      
        }
      }
    }
          
    valores_optimizacion <- resultados[which.max(resultados$auc), ]
    return(valores_optimizacion)
}


valores_depth = c(5,6,7,8,9,10,15,20)
valores_split = c(5,10,20,30)
valores_bucket = c(10,15,20, 30, 40, 50)

mejor_resultado <- optimizacion_arbol(train, val, test, valores_depth, valores_bucket, valores_split)
```


```{r visualizaciones}
#install.packages("ggplot2")
#library(ggplot2)

#ggplot(resultados, aes(x = maxdepth, y = auc, color = factor(minsplit), group = interaction(minsplit, minbucket))) +
#  geom_line() +
#  geom_point() +
#  labs(
#    title = "Impacto de maxdepth en AUC-ROC para diferentes combinaciones de minsplit y minbucket",
#    x = "maxdepth",
#    y = "AUC-ROC",
#    color = "minsplit"
#  ) +
#  theme_minimal()

#ggplot(resultados, aes(x = maxdepth, y = auc, color = factor(minsplit), group = interaction(minsplit, minbucket))) +
#  geom_line() +
#  geom_point() +
#  labs(
#    title = "Impacto de maxdepth en AUC-ROC para diferentes combinaciones de minsplit y minbucket",
#    x = "maxdepth",
#    y = "AUC-ROC",
#    color = "minsplit"
#  ) +
#  theme_minimal()
```


# Ejercicio 6
Con los parámetros encontrados en el punto anterior, se genera el árbol de decisión obtimizado y su visualización, además de comparar su rendimiento con el obtenido en el punto 3.
```{r}
tree_optimizado <-  rpart(formula=DRK_YN ~ .,
          data = train, 
          method = "class",
          control = rpart.control(
            cp = 0,          
            xval = 0,        
            maxdepth = mejor_resultado$maxdepth,
            minsplit = mejor_resultado$minsplit,
            minbucket= mejor_resultado$minbucket
          )
      )
rpart.plot(tree_optimizado)
```
Como es notorio, este árbol resulta mucho más complejo y de análisis de variables mucho más exhaustivo que el anterior. Para mejor comparación en cuanto a sus diferencias en rendimiento y capacidad predictiva, tomamos el valor de auc-roc del nuevo modelo respecto al conjunto de test, y comparamos dicho valor al obtenido con el modelo anterior que era de `r auc_roc`.
```{r auc}
obs = test$DRK_YN #valor verdadero
pred = predict(tree_optimizado,test,type="prob")[, "1"]
auc_roc_optimizacion <- auc(obs,pred)
```
Se puede analizar cómo es mejorado el valor de auc-roc en este modelo optimizado, con el cual casi llega a 0.8, lo cual es indicativo de una mejora predictiva de alrededor de 8 puntos respecto al modelo anterior. 

A continuación, para continuar viendo diferencias respecto al árbol planteado en el ejercicio 3, se analizan las variables principales de este nuevo modelo:
```{r variables}
variable_importance <- tree_optimizado$variable.importance
barplot(sort(variable_importance, decreasing = TRUE), 
        main = "Importancia de las Variables Predictoras",
        xlab = "Variables",
        ylab = "Importancia",
        las = 2,          # Rotar las etiquetas en el eje x
        col = "pink")

```

Las variables más importantes continúan siendo las mismas, pero ahora sí se ven más representadas en el árbol obtenido, lo cual resulta visible a partir de las diferencias entre los plots.

# Ejercicio 7
Para poder asignar valores NA a cierta porción de las variables predictoras del dataset se crea la función asignar_na, con la cual pasandole por parámtro el porcentaje deseado, se puede modificar los valores del dataframe en todas las columnas exceptuando la de target a predecir.

```{r NAs}
asignar_na <- function(col, porcentaje){
  n <- length(col)
  cant_na <- ceiling(porcentaje/100*n)
  #indices donde seran reemplazados al azar los valores por NAs
  indices_na <- sample(seq_len(n), cant_na) 
  #asignacion de valor faltante
  col[indices_na] <- NA
  
  return(col)
}
``` 

```{r conjuntos}
#Índices para la división de los datasets (itrain, ival) iguales a los ya obtenidos en el punto 3, con tal de asegurar que los datos en train, validacion y test son los mismos en cada versión

#
# 20% NAs en data
data_20pc_na <- data
data_20pc_na[,-which(names(data) == "DRK_YN")] <- lapply(data_20pc_na[,-which(names(data) == "DRK_YN")], asignar_na, porcentaje = 20)

#Creo los conjuntos de train, validacion y test con 20% NAs
train_20 <- data_20pc_na[itrain, ]
resto <- data_20pc_na[-itrain,]
val_20 <- resto[ival,]
test_20 <- resto[-ival,]

#
# 50% NAs en data
data_50pc_na <- data
data_50pc_na[,-which(names(data) == "DRK_YN")] <- lapply(data_50pc_na[,-which(names(data) == "DRK_YN")], asignar_na, porcentaje = 50)

#Creo los conjuntos de train, validacion y test con 50% NAs
train_50 <- data_50pc_na[itrain, ]
resto <- data_50pc_na[-itrain,]
val_50 <- resto[ival,]
test_50 <- resto[-ival,]

#
# 75% NAs en data
data_75pc_na <- data
data_75pc_na[,-which(names(data) == "DRK_YN")] <- lapply(data_75pc_na[,-which(names(data) == "DRK_YN")], asignar_na, porcentaje = 75)

#Creo los conjuntos de train, validacion y test con 75% NAs
train_75 <- data_75pc_na[itrain, ]
resto <- data_75pc_na[-itrain,]
val_75 <- resto[ival,]
test_75 <- resto[-ival,]
```


```{r tree 20%}
hiperparametros_20na <- optimizacion_arbol(train_20, val_20, test_20, valores_depth, valores_bucket, valores_split)
tree_20pc_na <-  rpart(formula=DRK_YN ~ ., data = train_20, method = "class",
          control = rpart.control(
            cp = 0,          
            xval = 0,        
            maxdepth = hiperparametros_20na$maxdepth,
            minsplit = hiperparametros_20na$minsplit,
            minbucket= hiperparametros_20na$minbucket
          )
      )
rpart.plot(tree_20pc_na)
```


```{r tree 50%}
hiperparametros_50na <- optimizacion_arbol(train_50, val_50, test_50, valores_depth, valores_bucket, valores_split)
tree_50pc_na <-  rpart(formula=DRK_YN ~ ., data = train_50, method = "class",
          control = rpart.control(
            cp = 0,          
            xval = 0,        
            maxdepth = hiperparametros_50na$maxdepth,
            minsplit = hiperparametros_50na$minsplit,
            minbucket= hiperparametros_50na$minbucket
          )
      )
rpart.plot(tree_50pc_na)
```


```{r tree 75%}
hiperparametros_75na <- optimizacion_arbol(train_75, val_75, test_75, valores_depth, valores_bucket, valores_split)
tree_75pc_na <-  rpart(formula=DRK_YN ~ ., data = train_75, method = "class",
          control = rpart.control(
            cp = 0,          
            xval = 0,        
            maxdepth = hiperparametros_75na$maxdepth,
            minsplit = hiperparametros_75na$minsplit,
            minbucket= hiperparametros_75na$minbucket
          )
      )
rpart.plot(tree_75pc_na)
```


```{r comparacion_aucroc}
obs = test_20$DRK_YN
pred = predict(tree_20pc_na,test,type="prob")[, "1"]
auc_roc_20 <- auc(obs,pred)

obs = test_50$DRK_YN
pred = predict(tree_50pc_na,test,type="prob")[, "1"]
auc_roc_50 <- auc(obs,pred)

obs = test_75$DRK_YN
pred = predict(tree_75pc_na,test,type="prob")[, "1"]
auc_roc_75 <- auc(obs,pred)
```

El auc-roc va disminuyendo a medida que aumentan los NAs presentes en los datasets. Se deteriora la capacidad predictiva del modelo.